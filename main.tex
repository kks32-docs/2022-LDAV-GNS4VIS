\documentclass{vgtc}
\usepackage[utf8]{inputenc}
\usepackage{cleveref}
\usepackage{xcolor}
\usepackage{pgfplots}
\usepackage{subfig}
\usepackage{booktabs}
\usepackage{caption}


%%
\ifpdf%                                % if we use pdflatex
  \pdfoutput=1\relax                   % create PDFs from pdfLaTeX
  \pdfcompresslevel=9                  % PDF Compression
  \pdfoptionpdfminorversion=7          % create PDF 1.7
  \ExecuteOptions{pdftex}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.pdf,.png,.jpg,.jpeg} % for pdflatex we expect .pdf, .png, or .jpg files
\else%                                 % else we use pure latex
  \ExecuteOptions{dvips}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.eps}     % for pure latex we expect eps files
\fi%

%% it is recomended to use ``\autoref{sec:bla}'' instead of ``Fig.~\ref{sec:bla}''
\graphicspath{{figures/}{pictures/}{images/}{./}} % where to search for the images

\usepackage{microtype}                 % use micro-typography (slightly more compact, better to read)
\PassOptionsToPackage{warn}{textcomp}  % to address font issues with \textrightarrow
\usepackage{textcomp}                  % use better special symbols
\usepackage{mathptmx}                  % use matching math font
\usepackage{times}                     % we use Times as the main font
\renewcommand*\ttdefault{txtt}         % a nicer typewriter font
\usepackage{cite}                      % needed to automatically sort the references
\usepackage{tabu}                      % only used for the table example
\usepackage{booktabs}                  % only used for the table example
%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.


%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{0}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}

%% allow for this line if you want the electronic option to work properly
\vgtcinsertpkg

\newcommand{\fix}[1]{\textcolor{red}{\textbf{\textit{TODO: #1}}}}
\newcommand{\code}[1]{\texttt{#1}}

\title{Minority Report: A Graph Network Oracle for In Situ Visualization}
\author{Krishna Kumar, Paul Navratil, Andrew Solis, Joseph Vantassel}
\date{April 2022}

\teaser{
  \centering
  \includegraphics[width=\linewidth]{figs/overview.png}
  \caption{Overview of GNS-informed in situ visualization. (a) A GNS is trained on granular flow trajectories, (b) the trained GNS predicts the dynamics of the domain, (c) human-in-loop to identify appropriate camera configurations and select relevant features to render, and (d) set-up and run in situ visualization of CB-Geo MPM simulation of granular flow with TACC Galaxy.}
  \label{fig:teaser}
}

%% Abstract section.
\abstract{In situ visualization techniques are hampered by a lack of foresight: crucial simulation phenomena can be missed due to a poor sampling rate or insufficient detail at critical timesteps. Keeping a human in the loop is impractical, and defining statistical triggers can be difficult. This paper demonstrates the potential for using a machine-learning-based simulation surrogate as an oracle to identify expected critical regions of a large-scale simulation. These critical regions are used to drive the in situ analysis, providing greater data fidelity and analysis resolution with an equivalent I/O budget to a traditional in situ framework. We develop a distributed asynchronous in situ visualization by integrating TACC Galaxy with CB-Geo MPM for material point simulation of granular flows. We employ a PyTorch-based 3D Graph Network Simulator (GNS) trained on granular flow problems as an oracle to predict the dynamics of granular flows. Critical regions of interests are manually tagged in GNS for in situ rendering in MPM.%
} % end of abstract

%% ACM Computing Classification System (CCS). 
%% See <http://www.acm.org/about/class> for details.
%% We recommend the 2012 system <http://www.acm.org/about/class/class/2012>
%% For the 2012 system use the ``\CCScatTwelve'' which command takes four arguments.
%% The 1998 system <http://www.acm.org/about/class/class/2012> is still possible
%% For the 1998 system use the ``\CCScat'' which command takes four arguments.
%% In both cases the last two arguments (1998) or last three (2012) can be empty.

\CCScatlist{
  \CCScatTwelve{Human-centered computing}{Visu\-al\-iza\-tion}{Visu\-al\-iza\-tion techniques}{Treemaps};
  \CCScatTwelve{Human-centered computing}{Visu\-al\-iza\-tion}{Visualization design and evaluation methods}{}
}


\begin{document}

\firstsection{Introduction}

\maketitle

% \section{Outline}

% \begin{itemize}
%     \item{Intro}
%     \begin{itemize}
%         \item In situ visualization on large data is complicated by long wait times between frames as the simulation evolves
%         \begin{itemize}
%             \item need timings for avg compute time per timestep in MPM
%         \end{itemize}
%         \item Interactivity is only possible after a simulation run, either on decimated data \cite{ sampling papers} or from offline in situ methods \cite{Cinema, Catalyst, libsim}.
%         \item  \textbf{Goal:} use GNS to identify critical regions in MPM sim evolution, target I/O (either only writes or higher-frequency writes) for these regions
%         \item   \textbf{Benefits:} 
%         \begin{itemize}
%             \item Interactive visualization of MPM sim using GNS
%             \item Lower I/O cost (fewer writes) and/or better analysis at same I/O cost (same write budget, targeted to critical timesteps)
%             \item ensemble ability within GNS to target key evolution steps \emph{across} simulation parameters, micro-targeting analysis to inter-simulation deltas
%         \end{itemize}
%     \end{itemize} 
%     \item {Related Work}
%     \begin{itemize}
%         \item Hopefully no one has already done this...
%         \item DL/NN simulation surrogates
%         \item DL/NN simulation surrogates for vis (Ohio State work)
%         \item in situ triggers (Alpine work) 
%     \end{itemize}
%     \item {Methodology}
%     \begin{itemize}
%         \item Run trained GNS for sim with human annotation for "interesting" spots
%         \item Confirm interactivity for GNS in situ analysis (delta fps with MPM-Galaxy CiSE paper)
%         \item Run MPM focusing I/O only on these timesteps \item Measure I/O savings compared to 'usual' MPM I/O cadence
%         \item Find an ensemble sequence where the phenomenon only occurs in a subset, and show how GNS in situ enables rapid viewing, compare against regular MPM in situ costs
%     \end{itemize}
    
    
%     \item {Results}
%     \begin{itemize}
%         \item They  will be real, and they will be spectacular!
%     \end{itemize}
%     \item{Future Work}
%     \begin{itemize}
%         \item Profit!
%     \end{itemize}
% \end{itemize}

% \section{Introduction}

In situ visualization only approximates a traditional post hoc analysis workflow. This approximation takes one of three modes: (1) an analyst interacts directly with a visualization interface connected to the running simulation ("human-in-the-loop"); (2) pre-scripted analyses are run against the simulation, either at a scheduled interval or when triggered by simulation state ("scripted"); or (3) simulation data is decimated (in time, space, data elements, or some combination) and saved for post hoc analysis ("decimation"). Each of these modes risks missing critical simulation evolution by omitting critical timesteps, inability to express critical states to trigger analysis, or decimation data loss. More is needed to elevate the analytical power of in situ visualization to match post hoc visualization, where the data evolution can be rewound and replayed with different analysis foci.

In this paper, we propose using a machine learning (ML)-based simulation surrogate as an oracle to determine critical regions for in situ analysis. In our method, the ML surrogate provides interactive post hoc analysis capabilities, allowing the analyst to identify simulation parameters ranges, critical timesteps, and promising data regions using a less powerful computing platform (e.g., a laptop rather than a large distributed HPC cluster).  These observations are used to target traditional in situ analysis methods to generate the most relevant results with minimal excess generation. Our method saves \fix{significant} computation and I/O cost over traditional in situ methods alone through precise application of visualization methods in time and space (i.e., rather than a parameter sweep). We demonstrate these savings on a granular column collapse simulation and a graph network simulation surrogate.

Our work makes the following contributions: 
\begin{itemize}
    \item a dynamic graph neural network simulation surrogate able to predict dynamics among simulation particles and update the corresponding graph;
    \item a method leveraging the simulation surrogate to harvest metadata used to target full-scale in situ analysis; and
    \item a demonstration of our surrogate and method on a large-scale column collapse problem where emergent phenomena cannot be easily expressed in closed form.
\end{itemize}

\section{Related Work}
\label{sec:related}

This section places our current work in the context of other in situ approaches, particularly those that leverage machine learning and those that dynamically respond to data evolution. We refer readers to Childs et~al.~\cite{childs20insitu} and Childs, Bennett and Garth~\cite{childs22insitu} for broader discussions of recent in situ work. Our technique is similar in spirit to a metadata storage in situ data product, as characterized by Patchett and Ahrens~\cite{patchett18optimizing}, in that the observations collected from the ML surrogate provide the metadata used to focus full-scale in situ computations.

\subsection{Machine Learning Surrogates for In Situ}

Machine learning surrogates are gaining popularity for in situ applications since they can produce plausible output much faster than full-scale computation. GNN-Surrogate~\cite{shi22gnn} uses a convolutional graph neural network (GNN) simulation surrogate to model a fixed-mesh ocean simulation at several fixed levels of detail in order to facilitate parameter space exploration. While our work also uses a GNN, the modeled granular column collapse simulation evolution can (and typically does) induce large structural deformations such that the GNN must predict particle dynamics and dynamically update the graph structure. We also use the ML surrogate to optimize full-scale traditional in situ analysis rather than operating on the ML surrogate output itself, which enables our method to capture human-tagged phenomena that is difficult to capture via an automated method.

Other recent applications of ML surrogates train on visualization outputs (rather than the simulation data directly) for feature detection~\cite{dutta18insitu} and to explore parameter space~\cite{he20insitunet}. In contrast, our work uses an ML surrogate of the simulation itself to determine metadata for full-scale in situ analysis. 

\subsection{Data-driven In Situ Techniques}
Some in situ techniques leverage automated data queries and data condition sensing to guide their operation and thus focus their operation on critical data regions and timesteps. These can take the form of feature detection for analysis (e.g., \cite{dutta18insitu}), preserving detail under data decimation  (e.g., \cite{wang17sampling,biswas2018situ,biswas21sampling}), or invoking analysis methods only when certain data conditions are met (e.g., \cite{bennett2016trigger,larsen2018flexible,lawson21insitu}).


\section{Methodology}
\label{sec:method}

This section describes our dynamic graph GNN surrogate (GNS) for granular flow simulations using the Material Point Method (MPM)~\cite{kumar2019scalable,soga2016trends} and our method for using GNS to gather metadata for full-scale, full-resolution in situ visualization within MPM using Galaxy~\cite{abram18galaxy}. We refer interested readers to Abram et~al.~\cite{abram22insitu} for details of the in situ implementation.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{figs/gnn.png}
    \caption{Graph Neural Network simulation of n-body dynamics.}
    \label{fig:gnn}
\end{figure*}
\subsection{GNS for Large-Deformation Granular Flows}
Graph Neural Networks (GNNs)~\cite{scarselli2008graph} are state-of-the-art Geometric Deep Learning algorithms operating on graphs to represent rich relational information and local vertex features.  Graph Networks are effective in learning the interaction dynamics.  A graph network maps an input graph to an output graph with the same structure but potentially different vertex, edge, and global feature attributes.  Fig~\ref{fig:gnn} shows an overview of the GNN learning to simulate n-body dynamics.  The graph network spans the physical domain with vertices representing an individual or a collection of particles, and the edges connecting the vertices represent the local interaction between particles or clusters of particles.  The GNN learns the dynamics, such as momentum and energy exchange, through a form of messages passing~\cite{gilmer2017neural}, where latent information propagates between vertices via the graph edges.  GNN has three components: (a) Encoder, which embeds particle information to a latent graph, the edges are learned functions; (b) Processor, which allows data propagation and computes the nodal interactions across steps; and (c) Decoder, which extracts the relevant dynamics (e.g., particle acceleration) from the graph. 


GNN learns to predict the particle dynamics through message passing~\cite{sanchez2020learning}.  The GNN edge messages  ($e^\prime_k \leftarrow \phi^e(e_k, v_{r_k}, v_{s_k}, u)$) are a learned linear combination of the true forces.  The edge messages are aggregated at every node exploiting the principle of superposition $\bar{e_i^\prime} \leftarrow \sum_{r_k = i} e_i^\prime$.  The vertex then encodes the connected edge features and its local features using a neural network: $v_i^\prime \leftarrow \phi^v (\bar{e_i}, v_i, u)$.  The GNS implementation uses semi-implicit Euler integration to update the next state of the particles based on the predicted accelerations at the vertices.  We introduce physics-inspired simple inductive biases, such as an inertial frame that allows learning algorithms to prioritize one solution (constant gravitational acceleration) over another, reducing learning time.  We train the GNS model on small-scale granular collapse and collision problems with 1000 particles for 20 Million steps on NVIDIA A100 GPUs.  The trained model then accurately predicts (within 5\% of error compared to MPM simulations) the granular flow on an inclined plane with 10x the number of particles during its training.  GNN trained on trajectory data is generalizable to predict particle kinematics in complex boundary conditions not seen during training.  We developed an open-source PyTorch GNN simulator that can successfully predict the dynamics of fluid and particulate systems~\cite{Kumar_Graph_Network_Simulator_2022}.  The GNN simulator is scalable to 100,000 vertices and more than one million edges.


\subsection{GNS-driven In Situ Analysis}

We trained a GNS simulator on 30 different trajectory data for 5 million steps.  We then simulate the 3D granular column collapse experiment, an experiment that captures the dynamics of landslides. The GNS predicts the rollout, i.e., the runout dynamics of a small-scale 15k particles granular column collapse simulation.  GNS predicts the entire runout process from initiation to collapse for the duration of one second with a time step of 1E-5~s.  The GNS rollout prediction runs on a NVIDIA GPU A100 node on  LoneStar6~\cite{lonestar6} at the Texas Advanced Computing Center (TACC).  The GNS rollouts are written as \code{vtp} files for post-processing in ParaView~\cite{ayachit15paraview}.  The GNS only takes ~20s to predict the entire rollout including writing 500 \code{vtp} files.  We use ParaView rendering of GNS simulations to identify feature sets and camera views for in situ visualization.


Once the appropriate feature sets were analyzed to capture from within ParaView, the parameters were then set within galaxy for performing in situ visualization. TACC Frontera \cite{stanzione20frontera} was used for running the in situ experiments. A single node was utilized with a total of 56 cores on two sockets available, a clock rate of 2.7GHz nominal, and 192 GB DDR4 RAM. A different run was performed for different camera positions. Each run output an image for every 20 timesteps, similar to the settings used for MPM. A single galaxy process is run which receives data from MPM for create in situ visualizations. MPM was run in parallel across 26 cores. Galaxy records the time it takes to receive data from MPM, including re-partitioning so that partitions do not overlap. The time for setting up the acceleration structures to raytrace the particles is also recorded, along with the total rendering time.

\begin{itemize}
    \item use small GNS simulation that can be run locally (desktop or laptop)
    \item visualize it to find awesome science potential
    \item harvest metadata for awesome science: simulation parameters, timesteps, filters, viewpoints, etc.
    \item use metadata to target full-scale in situ runs
    \item enjoy awesome insights! get publications, get tenure, save the world
\end{itemize}


\section{Results}
\label{sec:results}

\begin{figure}[!ht]
    \subfloat[side-view (4,960 timestep) \label{subfig-side}]{%
      \includegraphics[width=0.2\textwidth]{figs/image-0248-1.png}
    }
    \hfill
    \subfloat[top-down view (4,960 timestep) \label{subfig-top}]{%
      \includegraphics[width=0.2\textwidth]{figs/image-0248-0.png}
    }
    
    \centering
    \subfloat[aerial view (4,900 timestep) \label{subfig-aerial}]{%
      \includegraphics[width=0.2\textwidth]{figs/image-0245-3.png}
    }
    \caption{Rendered views from in situ MPM runs}
    \label{fig:mpm-gxy-results}
 \end{figure}

\begin{figure}[htb]
\centering
\resizebox{0.45\textwidth}{!}{%
\begin{tikzpicture}
\begin{axis}[
	legend style={at={(0.5,-0.1)},
	anchor=north,legend columns=-1},
	ybar,
	bar width = 4.5,
	xtick={0, 1, 2, 3, 4, 5, 6},
	ylabel = Time (s),
	xticklabels={run0, run0\_1, run1, run2, run3, run4, run5},
	scaled y ticks= base 10:2
]
\addplot 
	coordinates {(0,0.052)(1,0.052)(2,0.052)(3,0.052)(4,0.052)(5,0.052)(6,0.052)};

\addplot 
	coordinates {(0, 0.012)(1, 0.013)(2,0.012)(3,0.012)(4,0.012)(5,0.012)(6,0.013)};

\addplot 
	coordinates {(0,0.163)(1,0.159)(2,0.158)(3,0.162)(4,0.166)(5,0.157)(6,0.165)};

\legend{Receive,Setup,Render}
\end{axis}
\end{tikzpicture}
}
\caption{Graph of time for each in situ run. The breakdown shows the time spent for : Galaxy receiving data, setting up for rendering, and the rendering time}
\end{figure}

% \begin{table}[h!]
%     \centering
%     \caption{Runtimes for each runs part with respect to receiving data, setting up for in situ, and rendering}
%     \label{tab:my_label}
%     \begin{tabular}{c c c c} 
%      \toprule
%      Run & Recv (s) & Setup (s) & Render (s)\\ 
%      \midrule
%      run\_0 & $0.052 \pm 0.000$ & $0.012 \pm 0.001$ & $0.163 \pm 0.004$\\ 
%      run\_0\_1 & $0.052 \pm 0.000 $ & $0.013 \pm 0.001$ & $0.159 \pm 0.005$\\ 
%      run\_1 & $0.052 \pm 0.000$ & $0.012 \pm 0.001$ & $0.163 \pm 0.001$\\ 
%      run\_2 & $0.052 \pm 0.000$ & $0.012 \pm 0.002$ & $0.162 \pm 0.005$\\ 
%      run\_3 & $0.052 \pm 0.000$ & $0.012 \pm 0.002$ & $0.166 \pm 0.006$\\ 
%      run\_4 & $0.052 \pm 0.000$ & $0.012 \pm 0.001$ & $0.157 \pm 0.003$\\ 
%      run\_5 & $0.052 \pm 0.000$ & $0.012 \pm 0.002$ & $0.165 \pm 0.003$\\ 
%      \bottomrule
%     \end{tabular}
% \end{table}

\begin{table}[h!]
    \centering
    \caption{Total runtime for each in situ vis with MPM run}
    \label{tab:my_label}
    \begin{tabular}{l c} 
     \toprule
     Run & Runtime \\ 
     \midrule
     run\_0 & 423 s\\ 
     run\_0\_1 & 511 s \\ 
     run\_1 & 504 s\\ 
     run\_2 & 486 s\\ 
     run\_3 & 420 s \\ 
     run\_4 & 412 s \\ 
     run\_5 & 612 s \\ 
     \bottomrule
    \end{tabular}
\end{table}

Detailed metrics of the runs are shown in the following images and tables. Figure {show ref number} shows the time for each respective in situ run with MPM and Galaxy. The three metrics gathered (time to receive data, time for setup, and rendering time) are shown for each run in seconds. From it we can infer that the runtimes were relatively similar. 

\begin{itemize}
    \item observation examples using small-scale GNS
    \item generate full-scale in situ analysis using metadata from observations
    \item compare targeted in situ against: (1) constant-rate in situ (miss timesteps, bad viewing angle, excess images/analysis generated); (2) triggered in situ (cannot describe phenomenon for trigger, miss interesting start / end phase due to trigger granularity); (3) higher frequency data saves for post hoc analysis (prohibitively expensive IOPS budget)
\end{itemize}

\section{Future Work}
\label{sec:futurework}
We present GNS-informed in situ visualizations for large-deformation granular flow problems. We provide an example simulation of granular column collapse, a classical granular physics problem that captures the dynamics of a landslide. However, we have scaled the GNS-informed in situ approach to run 100,000 particles. A regional-scale landslide simulation would require millions to billions of particles. GNS is capable of predicting systems that are larger than the problem domains used in the training dataset. For GNS-informed visualization, we hope to run a coarse-scale GNS prediction of the landslide evolution and identify appropriate viewports, camera angles, and features. Abrams et~al~\cite{abram22insitu} simulated a regional-scale runout of the Oso landslide with 5 million material points (see fig.~\ref{fig:oso}). However, this required several trials to obtain the correct view and parameters to render. Using the GNS-informed in situ visualization approach, we can pre-determine the correct viewports and rendering parameters. Using these preset configurations, we will run a distributed asynchronous ray tracing with Galaxy and multi-node parallel MPM simulation of the landslide. The GNS-informed in situ approach offers the best of both worlds of in situ visualizations of peta- and exascale simulations while retaining the benefits of post hoc visualization through GNS predicted trajectories.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/oso.png}
    \caption{Distributed asynchronous rendering of the Oso landslide with TACC Galaxy and CB-Geo MPM.}
    \label{fig:oso}
\end{figure}

\section{Conclusion}
\label{sec:conclusion}

\section{Acknowledgements}
\label{sec:ack}
The authors would like to thank Dr Greg Abrams for fruitful discussions and help with the Galaxy set-up for in situ visualization. Krishna Kumar would like to thank the U.S. National Science Foundation grant CMMI-2022469 and OAC-2103937.
\bibliographystyle{plain}
\bibliography{gns4vis}

\end{document}
